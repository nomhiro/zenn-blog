---
title: "AMD Ryzen AI NPUã§Microsoft Phi-4ã‚’å‹•ä½œã•ã›ã‚‹æŠ€è¡“èª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆ"
emoji: "ðŸˆ"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["AI", "NPU", "phi4", "AMD", "ONNX"]
published: false
---

# ã¯ã˜ã‚ã«
ä»¥å‰ã®ã“ã¡ã‚‰ã®ãƒ–ãƒ­ã‚°ã§ã¯ã€Foundry Local ã‚’ä½¿ã„ã€SLMï¼ˆphi-4ãªã©ï¼‰ã‚’CPUã‚„GPUãŒã‚ã‚‹ç’°å¢ƒã§åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã‚’æ›¸ãã¾ã—ãŸã€‚
https://zenn.dev/nomhiro/articles/slm-foundry-local-poc-01

ä»Šå›žã¯ã€AMD Ryzenâ„¢ AI 9 365 10ã‚³ã‚¢/20 ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ»ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ï¼ˆæœ€å¤§ 50 NPU TOPSï¼‰ã§ SLM ã‚’å‹•ã‹ã—ã¦ã€ã©ã®ãã‚‰ã„ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ã®å·®ãŒã‚ã‚‹ã®ã‹ç¢ºèªã—ã¦ã¿ã¾ã™ã€‚

# Microsoft Phi-4 æœ€æ–°ä»•æ§˜ã¨ãƒªãƒªãƒ¼ã‚¹æƒ…å ±

**Microsoft Phi-4**ã¯2024å¹´12æœˆ12æ—¥ã«æ­£å¼ãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸæœ€æ–°ã®å°è¦æ¨¡è¨€èªžãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚**14Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**ã‚’æŒã¤Dense decoder-only Transformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æŽ¡ç”¨ã—ã€**16Kãƒˆãƒ¼ã‚¯ãƒ³**ã®Inputã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥ã‚Œã‚‰ã‚Œã¾ã™ã€‚

- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ï¼š14Bï¼ˆ14å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼š40å±¤ã€40ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ‰
- åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒï¼š5120
- èªžå½™ã‚µã‚¤ã‚ºï¼š100,352ãƒˆãƒ¼ã‚¯ãƒ³
- è¨“ç·´ãƒ‡ãƒ¼ã‚¿ï¼š9.8T tokens

# AMD Ryzen AI NPUã§SLMã‚’å‹•ä½œã•ã›ã‚‹ã«ã¯ï¼Ÿ

**ONNX Runtime with DirectML**ã‚’ä½¿ã„ã¾ã™ã€‚DirectX 12ãƒ™ãƒ¼ã‚¹ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢åŠ é€Ÿã«ã‚ˆã‚Šã€åºƒç¯„ãªãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢äº’æ›æ€§ã‚’æä¾›ã—ã¾ã™ã€‚ç¾åœ¨ã®AMD Ryzen AI 300ã‚·ãƒªãƒ¼ã‚ºã§ã¯ã€NPU+iGPUã‚’å”èª¿ã•ã›ã‚‹**ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰**ãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚

**Vitis AI Execution Provider**ã¯ã€NPUå°‚ç”¨å®Ÿè¡Œã«ã‚ˆã‚‹ä½Žé›»åŠ›ãƒ»é«˜åŠ¹çŽ‡ãªæŽ¨è«–ã‚’æä¾›ã—ã¾ã™ã€‚INT8/BF16é‡å­åŒ–ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€ãƒ¢ãƒã‚¤ãƒ«ç”¨é€”ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚

## ONNXå¤‰æ›ã¨é–‹ç™ºç’°å¢ƒæ§‹ç¯‰ã®å…·ä½“çš„æ‰‹é †

### ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ã¨äº‹å‰æº–å‚™

**å¿…è¦ç’°å¢ƒ**ï¼š
- Windows 11 (build >= 22621.3527)
- Visual Studio 2022 Community
- 16GBä»¥ä¸Šã®RAM
- 50GBä»¥ä¸Šã®ç©ºãå®¹é‡

### NPUãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

ã“ã¡ã‚‰ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚
https://ryzenai.docs.amd.com/en/latest/inst.html

â€»å‰æ
- Windows11 : build 22621.3527 ä»¥é™
  - ã€ŒC++ ã‚’ä½¿ç”¨ã—ãŸãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—é–‹ç™ºã€ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨
- Visual Studio : 2022
- cmake : 3.26 ä»¥é™
    https://cmake.org/download/#latest
- Miniforge
    https://conda-forge.org/download/
    ä»¥ä¸‹ã®3ã¤ã®ç’°å¢ƒå¤‰æ•°PATHã«ä»¥ä¸‹ã®å€¤ã‚’è¨­å®šã—ã¦ãŠãã¾ã™ã€‚
    ãƒ»path\to\miniforge3\condabin
    ãƒ»path\to\miniforge3\Scripts
    ãƒ»path\to\miniforge3\
  - Python : latest version


RyzenAIã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ãƒ¼ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
https://account.amd.com/en/forms/downloads/ryzen-ai-software-platform-xef.html?filename=ryzen-ai-1.5.0.msi

MSIã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ãƒ¼ã‚’èµ·å‹•ã—ã€ç”»é¢ã®æŒ‡ç¤ºã«å¾“ã„ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

![](/images/onnx-runtime-npu-slm/2025-07-14-23-17-09.png)

![](/images/onnx-runtime-npu-slm/2025-07-14-23-17-21.png)

![](/images/onnx-runtime-npu-slm/2025-07-14-23-17-31.png)

![](/images/onnx-runtime-npu-slm/2025-07-14-23-17-43.png)

![](/images/onnx-runtime-npu-slm/2025-07-14-23-17-57.png)

![](/images/onnx-runtime-npu-slm/2025-07-15-15-34-04.png)

![](/images/onnx-runtime-npu-slm/2025-07-15-15-34-42.png)

### Pythonç’°å¢ƒã®æ§‹ç¯‰

ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹miniforgeã®ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚’é–‹ãã€å°‚ç”¨ç’°å¢ƒã‚’ä½œæˆã—ã¾ã™ã€‚
```powershell
conda create -n phi4-onnx python=3.11 -y
conda activate phi4-onnx
```

:::details å®Ÿè¡Œçµæžœ
```powershell
20_slm\onnx-runtime-npu-slm > conda create -n phi4-onnx python=3.11 -y
Channels:
 - conda-forge
Platform: win-64
Collecting package metadata (repodata.json): done
Solving environment: done

## Package Plan ##

  environment location: C:\Users\nom40\miniforge3\envs\phi4-onnx

  added / updated specs:
    - python=3.11


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    python-3.11.13             |h3f84c4b_0_cpython        17.4 MB  conda-forge
    setuptools-80.9.0          |     pyhff2d567_0         731 KB  conda-forge
    ------------------------------------------------------------
                                           Total:        18.1 MB

done
#
# To activate this environment, use
#
#     $ conda activate phi4-onnx
#
# To deactivate an active environment, use
#
#     $ conda deactivate
20_slm\onnx-runtime-npu-slm > conda activate phi4-onnx
```
:::

### Hugging Face CLI

Hugging Face ã® Webç”»é¢ã«ãƒ­ã‚°ã‚¤ãƒ³ã—ãŸã®ã¡ã€Access Token ã‚’ä½œæˆã—ã¾ã™ã€‚
![](/images/onnx-runtime-npu-slm/2025-07-15-22-20-22.png)

Writeæ¨©é™ã‚’ä»˜ã‘ã¾ã™ã€‚
![](/images/onnx-runtime-npu-slm/2025-07-15-22-21-09.png)

AccessTokenã‚’ã‚³ãƒ”ãƒ¼ã—ã¦æŽ§ãˆã¦ãŠãã¾ã™ã€‚

Hugging Face CLI ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```powershell
pip install -U "huggingface_hub[cli]"
```

èªè¨¼è¨­å®šã‚’ã—ã¾ã™ã€‚Writeæ¨©é™ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ã„ã¾ã™ã€‚
```powershell
huggingface-cli login
```

:::details å®Ÿè¡Œçµæžœ
```powershell
(phi4-onnx) C:\Users\nom40>huggingface-cli login

    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|
    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|
    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|
    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|
    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|

    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.
    Setting a new token will erase the existing one.
    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .
Token can be pasted using 'Right-Click'.
Enter your token (input will not be visible):
Add token as git credential? (Y/n) Y
Token is valid (permission: write).
The token `onnx-npu-slm` has been saved to C:\Users\nom40\.cache\huggingface\stored_tokens
Your token has been saved in your configured git credential helpers (manager).
Your token has been saved to C:\Users\nom40\.cache\huggingface\token
Login successful.
The current active token is: `onnx-npu-slm`
```
:::

ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹ã‚’ç¢ºèªã—ã¦ãŠãã¾ã—ã‚‡ã†ã€‚
```powershell
huggingface-cli whoami
```


## å¿…è¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```powershell
pip install onnx torch onnxruntime-genai transformers
pip install accelerate huggingface-hub pandas numpy psutil
```

### äº‹å‰æœ€é©åŒ–æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®åˆ©ç”¨ï¼ˆæŽ¨å¥¨ï¼‰

Microsoftå…¬å¼ãŒæä¾›ã™ã‚‹æœ€é©åŒ–æ¸ˆã¿ONNXãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€å¤‰æ›ä½œæ¥­ã‚’å¤§å¹…ã«ç°¡ç´ åŒ–ã§ãã¾ã™ã€‚

```powershell
# Microsoftå…¬å¼ã®ONNXãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
huggingface-cli download microsoft/Phi-4-mini-instruct-onnx --include cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/* --local-dir .
```

:::details å®Ÿè¡Œçµæžœ
```powershell
20_slm\onnx-runtime-npu-slm > huggingface-cli download microsoft/Phi-4-mini-instruct-onnx --include cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/* --local-dir .
Fetching 11 files:   0%|                                                                            | 0/11 [00:00<?, ?it/s]Downloading 'cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/model.onnx' to '.cache\huggingface\download\cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\ihhw_uFzBe-Y54_HOJQmXx4GS8A=.701aa5d185b6a782bc27104a990dd5b634fa507840b7c42f7ee6f1fb812d0b83.incomplete'
Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
Downloading 'cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/special_tokens_map.json' to '.cache\huggingface\download\cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\ahkChHUJFxEmOdq5GDFEmerRzCY=.aff38493227d813e29fcf8406e8e90062f1f031aa47d589325e9c31d89ac7cc3.incomplete'
Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
Downloading 'cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/config.json' to '.cache\huggingface\download\cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\8_PA_wEVGiVa2goH2H4KQOQpvVY=.ac65d86061d3d0d704ee2511fd0eb8713ef19eb6eedba17c3080a4165d5b933b.incomplete'
Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
Downloading 'cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/model.onnx.data' to '.cache\huggingface\download\cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\Lzxw0O44RMmhTgKWeQQ-MMzHFnE=.cb0267fa60befa1a4ade8c98b6d32a3d67f51abbd307c7f793f132e8d9092131.incomplete'
Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
Downloading 'cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/genai_config.json' to '.cache\huggingface\download\cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\yDyKFBRCOr3XTWAm4EHNQUX0s3Y=.0fcfa1e663f2bc867f8dc62fae65dd0924f0a4d68b43d1234df742dd19171470.incomplete'
Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
Downloading 'cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/added_tokens.json' to '.cache\huggingface\download\cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\SeqzFlf9ZNZ3or_wZAOIdsM3Yxw=.d4f2aceb0f20b71dd1f4bcc7e052e4412946bf281840b8f83d39f259571af486.incomplete'
Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
Downloading 'cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/merges.txt' to '.cache\huggingface\download\cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\PtHk0z_I45atnj23IIRhTExwT3w=.dcecc4524288b351bbd0da8028e74e9b5bcdb9b5.incomplete'
Downloading 'cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/configuration_phi3.py' to '.cache\huggingface\download\cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\vEnnZuZbPjs88GEHAS5wEyJ0R4s=.01446e12bf573a1e96c8aa9c7af73a05e2096dec.incomplete' 
configuration_phi3.py: 10.9kB [00:00, 31.5MB/s]
Download complete. Moving file to cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\configuration_phi3.py
merges.txt: 2.42MB [00:00, 12.8MB/s] ?B/s]
Download complete. Moving file to cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\merges.txt
Downloading 'cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/tokenizer.json' to '.cache\huggingface\download\cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\HgM_lKo9sdSCfRtVg7MMFS7EKqo=.382cc235b56c725945e149cc25f191da667c836655efd0857b004320e90e91ea.incomplete'
Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
genai_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.52k/1.52k [00:00<00:00, 17.4MB/s]
Download complete. Moving file to cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\genai_config.json0/1.52k [00:00<?, ?B/s]
special_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 587/587 [00:00<00:00, 588kB/s]
config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.50k/2.50k [00:00<00:00, 5.05MB/s] 
Download complete. Moving file to cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\special_tokens_map.jsonM [00:00<?, ?B/s] 
Download complete. Moving file to cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\config.json | 0.00/2.50k [00:00<?, ?B/s] 
added_tokens.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 249/249 [00:00<00:00, 3.90MB/s]
Download complete. Moving file to cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\added_tokens.json0/4.86G [00:00<?, ?B/s] 
Fetching 11 files:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                             | 1/11 [00:00<00:09,  1.08it/s]Downloading 'cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/tokenizer_config.json' to '.cache\huggingface\download\cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\vzaExXFZNBay89bvlQv-ZcI6BTg=.c565326a315fbe62cda093a59d298828c8f3f823122661325f41f3ba577a7dec.incomplete'
Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
Downloading 'cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/vocab.json' to '.cache\huggingface\download\cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\j3m-Hy6QvBddw8RXA1uSWl1AJ0c=.6cb65a857824fa6615bb1782d95d882617a8bbce1da0317118586b36f39e98bd.incomplete'
Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.96k/2.96k [00:00<00:00, 24.2MB/s]
Download complete. Moving file to cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\tokenizer_config.json
vocab.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.91M/3.91M [00:01<00:00, 2.74MB/s]
Download complete. Moving file to cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\vocab.json/4.86G [00:01<04:54, 16.4MB/s]
tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15.5M/15.5M [00:02<00:00, 7.53MB/s]
Download complete. Moving file to cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\tokenizer.json5M [00:01<00:00, 6.74MB/s]
model.onnx: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52.1M/52.1M [00:03<00:00, 15.8MB/s]
Download complete. Moving file to cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\model.onnx/4.86G [00:02<04:20, 18.4MB/s]
model.onnx.data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.86G/4.86G [02:03<00:00, 39.3MB/s]
Download complete. Moving file to cpu_and_mobile\cpu-int4-rtn-block-32-acc-level-4\model.onnx.dataG [02:03<00:00, 43.9MB/s]
Fetching 11 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [02:04<00:00, 11.31s/it] 
C:\Users\nom40\Documents\PoC\20_slm\onnx-runtime-npu-slm
```
:::

### ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã®é‡å­åŒ–

AMD Quarkã‚’ä½¿ç”¨ã—ãŸåŠ¹çŽ‡çš„ãªé‡å­åŒ–ãŒå¯èƒ½ã§ã™ã€‚

quark-aiã®Zipã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦å›žç­”ã—ã¦ãŠãã¾ã—ã‚‡ã†ã€‚
https://quark.docs.amd.com/release-0.5.0/install.html

```powershell
# AMD Quarkã‚’ä½¿ç”¨ã—ãŸ4-bité‡å­åŒ–
pip install quark-0.5.0+fae64a406\quark-0.5.0+fae64a406-py3-none-any.whl
```

```python
# é‡å­åŒ–ã®å®Ÿè¡Œ
python -c "
import quark
quantizer = ModelQuantizer(
    model=model,
    quantization_config={
        'weight_bits': 4,
        'activation_bits': 8,
        'method': 'awq'
    }
)
quantized_model = quantizer.quantize()
"
```

### NPUã§ã®å®Ÿè¡Œè¨­å®š

```python
import onnxruntime as ort

# Vitis AI Execution Provider ã®è¨­å®š
providers = ['VitisAIExecutionProvider', 'CPUExecutionProvider']
session_options = ort.SessionOptions()
session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL

# NPUç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ä½œæˆ
session = ort.InferenceSession(
    "phi4_quantized.onnx",
    providers=providers,
    sess_options=session_options
)
```

## 4. æ€§èƒ½æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ï¼šCPU vs NPU

### æŽ¨è«–é€Ÿåº¦ã¨ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ

**AMD Ryzen AI Max+ 395ã§ã®å®Ÿæ¸¬å€¤**ï¼š
- **æŽ¨è«–é€Ÿåº¦**ï¼šIntel Core Ultra 7 258Væ¯”ã§**2.1å€é«˜é€Ÿ**
- **Time to First Token**ï¼šå°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§**æœ€å¤§4å€**ã€14Bãƒ¢ãƒ‡ãƒ«ã§**æœ€å¤§12.2å€é«˜é€Ÿ**
- **ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ**ï¼š50.7 tokens/secondï¼ˆLlama 3.2 1Bï¼‰

### é›»åŠ›åŠ¹çŽ‡

NPUä½¿ç”¨æ™‚ã¯**CPUé›»åŠ›æ¶ˆè²»ã‚’10-15%å‰Šæ¸›**ã—ã€é•·æ™‚é–“å®Ÿè¡Œã§ã®ãƒãƒƒãƒ†ãƒªãƒ¼å¯¿å‘½å»¶é•·åŠ¹æžœã‚’æä¾›ã—ã¾ã™ã€‚æŒç¶šçš„AIå‡¦ç†ã§ã®é›»åŠ›åŠ¹çŽ‡ãŒå¤§å¹…ã«å‘ä¸Šã—ã¾ã™ã€‚

### ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡

**é‡å­åŒ–ãƒ¬ãƒ™ãƒ«åˆ¥ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**ï¼š
- **Q4 K M**ï¼ˆæŽ¨å¥¨ï¼‰ï¼šç´„8GBï¼ˆ14Bãƒ¢ãƒ‡ãƒ«ï¼‰
- **Q6/Q8**ï¼ˆé«˜ç²¾åº¦ï¼‰ï¼šç´„12-16GB
- **æœ€å¤§å¯¾å¿œ**ï¼š128GBçµ±åˆãƒ¡ãƒ¢ãƒªï¼ˆMax+ 395ï¼‰

Variable Graphics Memoryï¼ˆVGMï¼‰ã«ã‚ˆã‚Šã€æœ€å¤§96GB GPUå°‚ç”¨ãƒ¡ãƒ¢ãƒªã®ç¢ºä¿ãŒå¯èƒ½ã§ã™ã€‚

## 5. å®Ÿè£…æ™‚ã®æ³¨æ„ç‚¹ã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–

**NPUèªè­˜ã‚¨ãƒ©ãƒ¼**ï¼š
```
ã‚¨ãƒ©ãƒ¼: "Unknown platform. Exiting"
è§£æ±ºç­–: 
- NPU MCDM driver (Version: 32.0.203.280ä»¥ä¸Š) ã‚’ç¢ºèª
- BIOSã§NPUæœ‰åŠ¹åŒ–
- OEMå›ºæœ‰ã®ãƒ‰ãƒ©ã‚¤ãƒãƒ¼åˆ¶é™ç¢ºèª
```

**ãƒ¡ãƒ¢ãƒªä¸è¶³å•é¡Œ**ï¼š
```
ã‚¨ãƒ©ãƒ¼: "Could not find an implementation for EPContext"
è§£æ±ºç­–:
- Variable Graphics Memory (VGM)ã‚’Highã«è¨­å®š
- 16GBä»¥ä¸Šã®VGMæŽ¨å¥¨
- modelcachekey ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ã‚’å‰Šé™¤
```

### é‡å­åŒ–äº’æ›æ€§

**ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥å¯¾å¿œ**ï¼š
- **STX (HX370)**ï¼šW8A16 + W4ABF16 ã‚µãƒãƒ¼ãƒˆ
- **PHX (7840HS)**ï¼šW4ABF16ã®ã¿ã‚µãƒãƒ¼ãƒˆ
- **HPT (8845HS)**ï¼šW4ABF16ã®ã¿ã‚µãƒãƒ¼ãƒˆ

### ç¾è¡Œåˆ¶é™äº‹é …

- **ãƒãƒƒãƒã‚µã‚¤ã‚ºå›ºå®š**ï¼ˆbatch_size=1ï¼‰
- **LM Studioç›´æŽ¥NPUå¯¾å¿œ**æœªå®Ÿè£…ï¼ˆ2025å¹´3æœˆæ™‚ç‚¹ï¼‰
- **llama.cpp ãƒ™ãƒ¼ã‚¹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³**ã®NPUå¯¾å¿œé™å®šçš„

## 6. æœ€é©åŒ–ã®ã‚³ãƒ„ã¨æŽ¨å¥¨è¨­å®š

### ç”¨é€”åˆ¥æŽ¨å¥¨é‡å­åŒ–ãƒ¬ãƒ™ãƒ«

```
- æ—¥å¸¸ä¼šè©±ï¼šQ4 K Mï¼ˆæœ€é©ãƒãƒ©ãƒ³ã‚¹ï¼‰
- ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼šQ6/Q8ï¼ˆé«˜ç²¾åº¦ç¶­æŒï¼‰
- é«˜ç²¾åº¦è¦æ±‚ï¼šQ8ï¼ˆãƒ¡ãƒ¢ãƒªè¨±å®¹æ™‚ï¼‰
```

### ã‚·ã‚¹ãƒ†ãƒ è¨­å®š

**LM Studioè¨­å®š**ï¼š
- "manually select parameters"æœ‰åŠ¹åŒ–
- GPU Offload: MAXè¨­å®š
- VGM: Highãƒ¢ãƒ¼ãƒ‰æŽ¨å¥¨

**ã‚·ã‚¹ãƒ†ãƒ æœ€é©åŒ–**ï¼š
- Windows Power Mode: Performance
- æœ€æ–°AMD Software: Adrenalin Editionâ„¢
- NPU Mode: Performanceï¼ˆxrt-smiçµŒç”±ï¼‰

## 7. é–‹ç™ºç’°å¢ƒã¨ãƒ„ãƒ¼ãƒ«

### å¿…è¦ãªãƒ„ãƒ¼ãƒ«ãƒã‚§ãƒ¼ãƒ³

**ã‚³ã‚¢é–‹ç™ºãƒ„ãƒ¼ãƒ«**ï¼š
- **AMD Ryzen AI Software 1.5**ï¼šçµ±åˆã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ãƒ¼
- **ONNX Runtime GenAI 0.7.0**ï¼šæœ€æ–°ã®æŽ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³
- **AMD Quark**ï¼šåŠ¹çŽ‡çš„ãªé‡å­åŒ–ãƒ„ãƒ¼ãƒ«
- **Microsoft Olive**ï¼šè‡ªå‹•æœ€é©åŒ–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

**é–‹ç™ºæ”¯æ´ãƒ„ãƒ¼ãƒ«**ï¼š
- **GAIA**ï¼šã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
- **Lemonade SDK**ï¼šé«˜æ°´æº–Python API
- **TurnkeyML**ï¼šONNXæœ€é©åŒ–ãƒ„ãƒ¼ãƒ«ãƒã‚§ãƒ¼ãƒ³

### å®Ÿè£…ã‚µãƒ³ãƒ—ãƒ«

```python
class Phi4NPUInference:
    def __init__(self, model_path):
        self.tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-4-mini-instruct")
        
        # NPUç”¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®š
        providers = ['VitisAIExecutionProvider', 'CPUExecutionProvider']
        session_options = ort.SessionOptions()
        session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
        
        self.session = ort.InferenceSession(
            model_path,
            providers=providers,
            sess_options=session_options
        )
    
    def generate_text(self, prompt, max_length=128):
        # å…¥åŠ›ã®ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
        inputs = self.tokenizer(
            prompt,
            return_tensors="np",
            padding=True,
            truncation=True,
            max_length=max_length
        )
        
        # NPUã§ã®æŽ¨è«–å®Ÿè¡Œ
        outputs = self.session.run(
            None,
            {
                "input_ids": inputs["input_ids"].astype(np.int64),
                "attention_mask": inputs["attention_mask"].astype(np.int64)
            }
        )
        
        # çµæžœã®ãƒ‡ã‚³ãƒ¼ãƒ‰
        logits = outputs[0]
        predicted_ids = np.argmax(logits, axis=-1)
        generated_text = self.tokenizer.decode(predicted_ids[0], skip_special_tokens=True)
        
        return generated_text
```

## 8. ä»Šå¾Œã®å±•æœ›ã¨èª²é¡Œ

### æŠ€è¡“çš„æ”¹å–„ç‚¹

**è¿‘ã„å°†æ¥ã®æ”¹å–„äºˆå®š**ï¼š
- **ROCm 7.0**ï¼ˆ2025å¹´Q3ï¼‰ã§ã®NPUã‚µãƒãƒ¼ãƒˆæ‹¡å¤§
- **Windows ROCm**æ­£å¼ã‚µãƒãƒ¼ãƒˆï¼ˆ2025å¹´å¾ŒåŠï¼‰
- **å‹•çš„é‡å­åŒ–**å¯¾å¿œã®æ‹¡å……
- **ãƒãƒƒãƒã‚µã‚¤ã‚º**å¯å¤‰å¯¾å¿œ

### ç¾åœ¨ã®èª²é¡Œ

**æŠ€è¡“çš„åˆ¶é™**ï¼š
- ç¬¬ä¸€ä¸–ä»£NPUæŠ€è¡“ã®æˆç†Ÿåº¦
- ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ç”Ÿæ…‹ç³»ã®ç™ºå±•æ®µéšŽ
- ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ é–“ã®äº’æ›æ€§å•é¡Œ

**é–‹ç™ºç’°å¢ƒã®èª²é¡Œ**ï¼š
- è¤‡é›‘ãªç’°å¢ƒæ§‹ç¯‰æ‰‹é †
- ãƒ‡ãƒãƒƒã‚°ãƒ„ãƒ¼ãƒ«ã®ä¸è¶³
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸è¶³

## æŠ€è¡“ãƒ–ãƒ­ã‚°è¨˜äº‹ä½œæˆæ™‚ã®æŽ¨å¥¨æ§‹æˆ

### è¨˜äº‹ã®æ§‹æˆæ¡ˆ

1. **å°Žå…¥**ï¼šPhi-4ã®æ¦‚è¦ã¨NPUæ´»ç”¨ã®æ„ç¾©
2. **æŠ€è¡“èƒŒæ™¯**ï¼šAMD Ryzen AI NPUã®ç‰¹å¾´ã¨åˆ©ç‚¹
3. **å®Ÿè£…æ‰‹é †**ï¼šæ®µéšŽçš„ãªç’°å¢ƒæ§‹ç¯‰ã¨ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰
4. **æ€§èƒ½è©•ä¾¡**ï¼šå…·ä½“çš„ãªãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯çµæžœ
5. **ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°**ï¼šã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–
6. **æœ€é©åŒ–ã®ã‚³ãƒ„**ï¼šå®Ÿç”¨çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹å‘ä¸Šæ‰‹æ³•
7. **ä»Šå¾Œã®å±•æœ›**ï¼šæŠ€è¡“å‹•å‘ã¨æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„ç‚¹

### èª­è€…ã¸ã®é…æ…®

- **åŸºæœ¬çš„ãªæ‰‹é †**ã‚’ä¸å¯§ã«èª¬æ˜Ž
- **å…·ä½“çš„ãªã‚³ãƒ¼ãƒ‰ã‚µãƒ³ãƒ—ãƒ«**ã‚’è±Šå¯Œã«æä¾›
- **ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°**æƒ…å ±ã‚’å……å®Ÿ
- **æ€§èƒ½ãƒ‡ãƒ¼ã‚¿**ã‚’æ•°å€¤ã§æ˜Žç¤º
- **æœ€æ–°æƒ…å ±**ã¸ã®ç¶™ç¶šçš„ãªæ›´æ–°ãŒå¿…è¦

## çµè«–

Microsoft Phi-4ã‚’AMD Ryzen AI NPUã§å‹•ä½œã•ã›ã‚‹æŠ€è¡“ã¯ã€2024å¹´å¾ŒåŠã‹ã‚‰2025å¹´å‰åŠã«ã‹ã‘ã¦æ€¥é€Ÿã«ç™ºå±•ã—ã¦ã„ã¾ã™ã€‚ç¾æ™‚ç‚¹ã§ã¯ä¸€éƒ¨åˆ¶é™ãŒã‚ã‚‹ã‚‚ã®ã®ã€é›»åŠ›åŠ¹çŽ‡ã¨æŽ¨è«–é€Ÿåº¦ã®å‘ä¸Šã«ã‚ˆã‚Šã€å®Ÿç”¨çš„ãªAIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®é–‹ç™ºãŒå¯èƒ½ã§ã™ã€‚

ç‰¹ã«**14Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**ã¨ã„ã†é©åº¦ãªã‚µã‚¤ã‚ºã®Phi-4ã¯ã€æ¶ˆè²»è€…å‘ã‘ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§ã®å®Ÿç”¨çš„ãªé‹ç”¨ã«é©ã—ã¦ãŠã‚Šã€AMD Ryzen AI NPUã®ç‰¹æ€§ã‚’æ´»ã‹ã—ãŸåŠ¹çŽ‡çš„ãªå®Ÿè£…ãŒæœŸå¾…ã§ãã¾ã™ã€‚æŠ€è¡“ãƒ–ãƒ­ã‚°è¨˜äº‹ã§ã¯ã€ã“ã‚Œã‚‰ã®æœ€æ–°å‹•å‘ã‚’è¸ã¾ãˆãŸå®Ÿè£…ã‚¬ã‚¤ãƒ‰ã¨æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ã‚’æä¾›ã™ã‚‹ã“ã¨ã§ã€èª­è€…ã«ã¨ã£ã¦ä¾¡å€¤ã®ã‚ã‚‹æŠ€è¡“æƒ…å ±ã‚’æä¾›ã§ãã‚‹ã§ã—ã‚‡ã†ã€‚